\documentclass{beamer}
\usecolortheme{CBS}
\usetheme{CBS}
% default settings for file listings
\usepackage{listings}
\lstset{
    basicstyle=\ttfamily\scriptsize,
    backgroundcolor=\color{yellow!10},
    emptyilines=1
}

% fonts for checkmarks
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%

\usepackage{soul}

\title{Part I: from Raw to technically correct data}
\author{\hfill Mark van der Loo and Edwin de Jonge}
\date{\hfill July 09 2013\\ \hfill\emph{useR!2013}}

\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\R}{\code{R}} %% call as \R{} to avoid extra spaces.


\usepackage{tikz}
\usetikzlibrary{shapes,arrows,decorations.pathreplacing}
  \tikzstyle{statpoint}=[
            fill=blue!10,
            draw, rectangle,
            rounded corners,
            text width=2.3cm,
            font=\scriptsize\bf\sf,
            node distance=1.4cm,
            align=center]
  \tikzstyle{arr}=[->,thick,>=stealth',color=black]
  \tikzstyle{action}=[right, font=\scriptsize\sf]
  \tikzstyle{file}=[
    fill=green!10,
    draw, rectangle,
    node distance=6cm,
    text width=2.3cm,
    font=\scriptsize\bf\sf,
    align=center
  ]
  \tikzstyle{store}=[->,thick,>=stealth',color=black]
  \tikzstyle{save}=[above,font=\scriptsize\sf]

\begin{document}

<<setup, include=FALSE, cache=FALSE>>=
library(knitr)
opts_chunk$set(size='scriptsize')
@
 
\CBStitleframe
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Statistical analyses}
\begin{frame}[fragile]
  \begin{tikzpicture}
    \node[statpoint] (raw) {Raw data};
    \node[statpoint, below of=raw] (input)   {Technically correct data};
    \node[statpoint, below of=input] (micro) {Consistent data};
    \node[statpoint, below of=micro] (stat)  {Statistical results};
    \node[statpoint, below of=stat] (output) {Formatted output};
    \draw[arr] (raw.south) to node[action]   {type checking, normalizing} (input.north);
    \draw[arr] (input.south) to node[action] {fix and impute} (micro.north);
    \draw[arr] (micro.south) to node[action] {estimate, analyze} (stat.north);
    \draw[arr] (stat.south) to node[action]  {tabulate, plot} (output.north);
    \draw[decorate,
      decoration={
        raise=6pt,
        brace,
        amplitude=10pt},
        thick](micro.west) -- 
                node[sloped,above=0.5cm,font=\scriptsize\sf] {data cleaning}
              (raw.west);

  \only<2->{
    \node[file,right of=raw] (pi) {pre-input};
    \draw[store,dotted] (raw.east) to node[save]{store} (pi.west);
  }
  \only<3->{
    \node[file,right of=input] (ip) {input};
    \draw[store,dotted] (input.east) to node[save]{store} (ip.west);
  }
  \only<4->{
    \node[file,right of=micro] (mi) {microdata};
    \draw[store,dotted] (micro.east) to node[save]{store} (mi.west);
    \node[file,right of=stat] (st) {stats};
    \draw[store,dotted] (stat.east) to node[save]{store} (st.west);
    \node[file,right of=output] (rp) {report};
    \draw[store,dotted] (output.east) to node[save]{store} (rp.west);
  }
  \end{tikzpicture}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Technically correct data}
\begin{frame}
\begin{block}{In \R{}}
\em Data, stored as a \code{data.frame}, with meaningful column names and each
column of the type that appropriately represents the value domain of the
corresponding variable.
\end{block}
\end{frame}
\note{
  That means: categorical as factor, text as character, numbers as numeric, etc.
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Getting there}
\begin{frame}
\begin{enumerate}
\item File conversion to an \R{} readable type (preferably \code{txt}-based).
\item Read line by line into \R{}
\item Select lines containing data.
\item Split lines into fields.
\item Order fields and recognize gaps.
\item Transform to \code{data.frame}
\item Normalize and coerce types.
\end{enumerate}
\only<1->{
  \begin{block}{Best practice}
      \em When importing a file from a foreign software, make that
      software responsible for exporting to an open format.
    \end{block}
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Scenarios}
\begin{frame}
  \begin{itemize}
    \item[auto] Read and convert in a single go (\code{read.table}).
    \item[$\tfrac{1}{2}$auto] Read all columns as \code{character} into \code{data.frame}, coerce and normalize by yourself.
    \item[DIY] Read line-by-line into \R{}; use text processing and coercion to interpret values.
  \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Tools}
\begin{frame}
  \includegraphics[width=\textwidth]{img/surgical_instruments}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{\code{read.table}}
\begin{frame}[fragile]
  \vspace{-2cm}
  \hfill\includegraphics[width=2.3cm]{img/swiss_army}

<<eval=FALSE>>=
read.table(file, header = FALSE, sep = "", quote = "\"'",
     dec = ".", row.names, col.names, as.is = !stringsAsFactors,
     na.strings = "NA", colClasses = NA, nrows = -1,
     skip = 0, check.names = TRUE, fill = !blank.lines.skip,
     strip.white = FALSE, blank.lines.skip = TRUE,
     comment.char = "#", allowEscapes = FALSE, flush = FALSE,
     stringsAsFactors = default.stringsAsFactors(),
     fileEncoding = "", encoding = "unknown", text)
@

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{frame}[fragile]
  \vspace{-2cm}
  \hfill\includegraphics[width=2.3cm]{img/swiss_army}

  Fully automated when:
  \begin{itemize}
    \item Field separator constant over lines and columns.
    \item Every field is automatically convertible:
    \begin{itemize}
      \item Constant decimal character over lines and columns.
      \item No (non-white) characters in number fields.
      \item Categories are spelled consistently.
    \end{itemize}
    \item Empty values only at end of lines.
    \item Consistent use of comment characters over lines.
    \begin{itemize}
      \item Use \code{flush=TRUE} when comments occur at the end of lines.
    \end{itemize}
  \end{itemize}

\end{frame}


\begin{frame}[fragile]
A note on the use of \code{colClasses}
<<>>=
# not using colClasses may yield character where you want numeric
read.table(text=
  "hello 3 \n world x")
@

<<tidy=FALSE>>=
# but using colClasses throws an error
read.table(text="hello 3 \n world x",
  colClasses=c("character","numeric"))
@
$\to$ Using \code{colClasses} makes reading a lot faster.
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Examples: t.c. in one go with \code{read.table}?}
\begin{frame}

\begin{tabular}{lc}
\only<1->{
  \lstinputlisting[firstline=1,lastline=2]{ex1.txt}
} & \only<2->{\cmark\hspace{1cm}\code{sep=";"}}\\

\end{tabular}\\
\begin{tabular}{lc}
  \only<3->{
  \lstinputlisting[firstline=4,lastline=6]{ex1.txt} 
  }&\only<4->{\xmark}
\end{tabular}\\
\begin{tabular}{lc}
  \only<5->{
  \lstinputlisting[firstline=8,lastline=10]{ex1.txt} 
  }&\only<6->{\cmark \hspace{1cm}\code{na.strings=c("N/A","?")}}
\end{tabular}\\
\begin{tabular}{lc}
  \only<7->{
  \lstinputlisting[firstline=12,lastline=14]{ex1.txt} 
  }&\only<8->{\xmark}
\end{tabular}\\
\begin{tabular}{lc}
  \only<9->{
  \lstinputlisting[firstline=16,lastline=18]{ex1.txt} 
  }&\only<10->{\xmark}
\end{tabular}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Type conversion}
{
\usebackgroundtemplate{
  \includegraphics[width=\paperwidth]{img/casting}  
}
\begin{frame}[fragile]
\end{frame}

}
\begin{frame}[fragile]
<<eval=TRUE,tidy=FALSE>>=
read.table(
  file="ex2.txt",
  sep=";",
  colClasses=rep('character',3),
  col.names=c("name","level","score")
)
@
\end{frame}

\begin{frame}
  \begin{itemize}
    \item Normalize, using text-tools, \emph{e.g.}
    \begin{itemize}
      \item Remove characters from numerical strings
      \item Replace decimal period with comma or \emph{vice versa}
      \item String normalisation: (un)capitalisation, trimming, padding,
        character replacement (\"e$\to$e, \ss$\to$ss)
      \item Reduce character vectors to categories\footnote{This overlaps with Part II.}
    \end{itemize}
    \item Coerce from \code{character}, using\\
      \begin{tabular}{ll}
        \code{as.numeric} & \code{factor}\\
        \code{as.integer} & \code{ordered}\\
        \code{as.logical} & 
      \end{tabular} \\
    or, for date extraction:\\
      \begin{tabular}{ll}
        \code{as.POSIXct} & \code{lubridate::mdy}.
      \end{tabular}
  \end{itemize}
\end{frame}

\section{Text processing}
\begin{frame}[fragile]
Simple character replacement with \code{chartr(old,new,x)}
<<>>=
# replace a->x and b->y
chartr("ab","xy",c("abba","AbBa"))
@

Case switching with \code{toupper(x)}, \code{tolower(x)}
<<>>=
toupper(c("Hello","worLd"))
tolower("hELlo WoRlD")
@
\end{frame}

\begin{frame}[fragile]
Removing characters with \code{gsub(pattern,replacement,x,fixed=TRUE)}

<<>>=
# remove all asterikses
gsub("*","",c("8*","8**"),fixed=TRUE)
@
\begin{block}{Note}
\code{fixed=TRUE} forces a literal interpretation of \code{*},
which has special meaning in \emph{regular expressions}.
\end{block}


\end{frame}


\begin{frame}
\begin{block}{\code{stringr}}
\em The \code{stringr} package [...] simplifies string operations by
eliminating options that you donâ€™t need 95\% of the time (the other 5\% of the
time you can use the base functions).\footnote{H. Wickham, R Journal \textbf{2}
38-40}
\end{block}

\end{frame}

\begin{frame}[fragile]
Padding: \code{str\_pad(string,width,side="left",pad=" ")}
<<>>=
library(stringr)
str_pad(c("1-555","01-555"),6,pad="0")
@
Trimming: \code{str\_trim(string,side="both")}
<<>>=
str_trim("  hello  ")
str_trim("  hello  ",side="left")
@
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Converting to numbers}
\begin{frame}[fragile]
<<>>=
# as.numeric expects decimal points
as.numeric(c("4.5","4"))

# note: as.integer truncates non-integers:
as.integer(c("3.2","3.7","3"))
@
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Converting to \code{factor}}
\begin{frame}[fragile]
Use \code{factor} not as.factor.
<<>>=
x <- c("high","low","high","high")
y <- as.factor(x)
table(y)
@

<<>>=
y <- factor(x,levels=c('high','medium','low'))
table(y)
@
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Converting dates}
\begin{frame}[fragile]
\begin{block}{\code{POSIXct} time/date format}
\begin{itemize}
  \item Stores a time/date point as nr seconds since 01-01-1970.
  \item Alows for meaningful sorting, subtraction.
  \item Conversion to calendar time/date depends on
  \begin{itemize}
    \item Calendar system
    \item Time zone
    \item Daylight saving times (DST)
    \item Leap days, leap seconds
  \end{itemize}
  \item Conversion from \code{character}
  \begin{itemize}
    \item Base \R{}: \code{as.POSIXct}
    \item \code{lubridate} package
  \end{itemize}
\end{itemize}
\end{block}
\end{frame}



\begin{frame}[fragile]
Using \code{lubrdidate}

<<>>=
library(lubridate)
dmy("I was born on 28 September 1976")
@
\uncover<2->{
\code{dmy} stands for day-month-year, others:
\begin{center}
  \begin{tabular}{lll}
    \code{dmy} & \code{myd} &\code{ydm}\\
    \code{mdy} & \code{dym} &\code{ymd}
  \end{tabular}
\end{center}
}
\end{frame}

\begin{frame}[fragile]
Caveats:
<<>>=
# multiple dates in a single string yields NA
dmy("28/09/76 16/09/77")
@

<<>>=
# Only certain substrings are recognized
dmy(c(
  "12 Sep 1974",
  "12 Sept 1974"
))
@
\end{frame}


\begin{frame}
Recognizable substrings
  \begin{tabular}{lll}
    \hline
    Code$^\dagger$       & description                             & Example  \\
    \hline
%    \code{\%a} & Abbreviated weekday$^*$      & \code{Mon}  \\
%    \code{\%A} & Full weekday$^*$             & \code{Monday}\\
    \code{\%b} & Abbreviated month$^*$        & \code{Sep} \\
    \code{\%B} & Full month$^*$               & \code{September}\\
    \code{\%m} & Month number (01-12)                           & \code{09}\\
    \code{\%d} & Day of the month (01-31).    & \code{28} \\
    \code{\%y} & Year without century (00-99)                   & \code{13}\\
    \code{\%Y} & Year including century.                        & \code{2013}\\
    \hline
  \end{tabular}\\
  {\scriptsize $^*$In current locale}\\
  {\scriptsize $^\dagger$When using \code{as.POSIXct}}
\end{frame}

\begin{frame}[fragile]
<<>>=
# you can specify the timezone
ymd("2013-07-09",tz="Europe/Madrid")
@
\begin{block}{Timezones}
\begin{itemize}
  \item Are an OS service (on Windows, a 3rd-party db is used)
  \begin{itemize}
    \item On \code{*ix} OS's look for \code{zone.tab}
    \item On \code{Windows} do \code{\$>tzutil /l}
  \end{itemize}
\item Are not constant: think of changing DST policies, etc.
\end{itemize}
\end{block}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Digging deeper}
\begin{frame}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Do It Yourself conversion}
\begin{frame}

\begin{tabular}{lp{5cm}}
 Read the file line by line as \code{text} & \code{readLines} \\
 Select lines containing data              & \code{grepl}     \\
 Split fields                              & \code{strsplit}\\
 Transform to \code{data.frame}            & \code{unlist, as.matrix, as.data.frame}\\
 Normalize field by field and coerce       & \code{agrep}, \code{stringdist}\\
\end{tabular}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Reading a file line by line}
\begin{frame}[fragile]
<<>>=
(v <- readLines("ex3.txt"))
@

\begin{block}{\code{readLines}}
\begin{itemize}
\item Returns a \code{character} vector.
\item Use $n=<number>$ to load only some test data.
\end{itemize}
\end{block}

\end{frame}

\section{Selecting lines}
\begin{frame}[fragile]
<<>>=
(I <- grepl("%",v))
(v <- v[!I])
@
\begin{block}{\code{grepl}}
  \begin{itemize}
    \item Use \code{fixed=TRUE} to ignore special characters.
    \item Special characters are \verb" . \ | ( ) [ {  ^ $ * + ?"
  \end{itemize}
\end{block}
\end{frame}


\section{Splitting fields}
\begin{frame}[fragile]
<<>>=
(L <- strsplit(v,split=c(";","[;,]",";")))
@
\begin{block}{\code{strsplit}}
\begin{itemize}
  \item Output is always a \code{list}.
  \item you may define different field splitters for elements of \code{v}.
  \item Use \code{fixed=TRUE} to ignore special characters.
\end{itemize}
\end{block}
\end{frame}

\section{Coerce to \code{data.frame}}
\begin{frame}[fragile]
<<>>=
M <- matrix(unlist(L), nrow=3, byrow=TRUE)
dat <- as.data.frame(M,stringsAsFactors=FALSE)
names(dat) <- c("name","level","value")
dat
@
\end{frame}

\section{Fuzzy text matching}
\begin{frame}[fragile]
\begin{block}{fuzzy matching}
\begin{itemize}
\item Count nr of basic operations turning string $s$ into $t$.
\item Basic operations include
\begin{itemize}
  \item deletion
  \item insertion
  \item substitution
  \item transposition\footnote{not in \code{agrep}}
\end{itemize}
\item Example: distance between \code{abc} and \code{bac} equals 1.
\end{itemize}

\end{block}
\end{frame}

\begin{frame}[fragile]
<<>>=
(I <- agrep("medium",dat$level,max.distance=2))
dat$level[I] <- "medium"
@
\begin{block}{\code{agrep}}
  \begin{itemize}
    \item Uses deletion, instertion and substitution
    \item Returns index of matching elements.
  \end{itemize}
\end{block}
\end{frame}

\begin{frame}[fragile]
<<message=FALSE>>=
library(stringdist)
(I <- stringdist("medium",dat$level) <= 1)
dat$level[I] <- "medium"
@
\begin{block}{\code{stringdist}}
  \begin{itemize}
    \item Uses deletion, instertion, substitution and transposition
    \item Returns string distance value
    \item Offers several string distance algorithms
  \end{itemize}
\end{block}
\end{frame}


\end{document}
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

With base \R{}
<<>>=
x <- c("1-555","01-555")
x <- paste("000000",x,sep="")
substr(x,nchar(x)-5,nchar(x))
@
 
<<boring-plots,dev="pdf",fig.width=5,fig.height=5,out.width=".45\\linewidth",par=TRUE>>=
## two plots side by side (option fig.show=hold)
boxplot(x)
hist(x,main='')
@
\end{frame}
 
\end{document}

