%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

\subsection{Data analysis}

\begin{quote}
Analysis of data is a process of inspecting, cleaning, transforming, and
modeling data with the goal of highlighting useful information, suggesting
conclusions, and supporting decision making.
\begin{flushright}
  \em{Wikipedia}
\end{flushright}
\end{quote}

In practice a data analyst spends a lot of time on preparing the data for
statistical analysis.  It is very rare that data are in the correct format, are
without errors, are complete and have labels and codes that are needed for
analysis. Data Cleaning is the process of transforming raw data into consistent
data that can be analyzed.

Data cleaning sounds like selectively manipulating your data, which is
considered bad scientific practice.  However not cleaning your data makes
statistical analysis impossible and may heavily bias the results of your
analysis.  Data cleaning should be seen as a statistical operation that
interprets raw data, removes known deficiencies, makes it technically correct
and consistent such that it is ready for further statistical analysis.  As
such, data cleaning methods should be documented and reproducible: When applied
on the same raw data, the result should be the same. This has the advantage
that when new raw data is available that exactly the same data cleaning steps
can be performed, making the analysis of old and new data comparable.

\R{} provides the right environment for data cleaning. Since \R{} is a
programming language all data cleaning steps can be executed in a reproducible
and documented manner.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\subsection{Statistical analysis in 5 steps}
In this paper we describe a typical statistical analysis as the result of a
number of data processing steps where each step increases the ``value'' of the
data. Figure \ref{fig:steps} shows an overview of a typical data analyses
project. Here, each rectangle represents a certain state of the data and the
arrows represent the activities needed to get from one state to the other.

\begin{wrapfigure}{l}{0.5\textwidth}
\begin{center}
  \begin{tikzpicture}
    \node[statpoint] (raw) {Raw data};
    \node[statpoint, below of=raw] (input)   {Technically correct data};
    \node[statpoint, below of=input] (micro) {Consistent data};
    \node[statpoint, below of=micro] (stat)  {Statistical results};
    \node[statpoint, below of=stat] (output) {Formatted output};
    \draw[arr] (raw.south) to node[action]   {type checking, normalizing} (input.north);
    \draw[arr] (input.south) to node[action] {fix and impute} (micro.north);
    \draw[arr] (micro.south) to node[action] {estimate, analyze} (stat.north);
    \draw[arr] (stat.south) to node[action]  {tabulate, plot} (output.north);
    \draw[decorate,
      decoration={
        raise=6pt,
        brace,
        amplitude=10pt},
        thick](micro.west) -- 
                node[sloped,above=0.5cm,font=\scriptsize\sf] {data cleaning}
              (raw.west);
  \end{tikzpicture}
\end{center}
\caption{Steps involved in a typical statistical analysis. With \textsl{data cleaning}
we understand all the activities necessary to get data in an analyzable format.}
\label{fig:steps}
\end{wrapfigure}
The first state (\textsf{Raw data}) is the data as it comes in. Often raw data
files contain no or faulty headers, wrong data types (\textsl{e.g.} numbers
stored as strings), wrong category labels, unknown or unexpected character
encoding and so on. In short, reading such files into an \R{}
\code{data.frame}  directly is either difficult or impossible without some sort
of preprocessing.

Once this preprocessing has taken place, data can be deemed \textsf{Technically
correct}.  That is, in this state data can be read into an \R{}
\code{data.frame}, with correct names, types and labels, without further
trouble. However, that does not mean that the values are error-free. For
example, an \emph{age} variable may be reported negative, an under-aged person
may be registered to possess a driver's license, or  data may simply be missing.
Such inconsistencies obviously depend on the subject matter that the data
pertains to, and they should be ironed out before valid statistical inference
from such data may be produced.

The \textsf{Consistent data} stage is the stage where data is ready for
trouble-free statistical inference.  Ideally, this can be done without taking
previous data cleaning steps into account. However, in many cases statistical
methods like imputation of missing values will influence statistical inference
based on the consistent data.

Once your \textsf{Statistical results} are produced you can store them for
reuse and finally, results can be \textsf{Formatted} to include in statistical
reports or publications.

\begin{tip}{Tip}
Store the input data for each stage (raw, technically correct,
consistent, aggregated and formatted) separately.  Each step
between the stages should be performed by a separate \code{R} script. This makes your
data analysis project reproducible.
\end{tip}

Summarizing, a statistical analyses can be separated in five stages, from raw
data to formatted output, where the quality of the data improves in every step
towards the final result. Data cleaning is related to the first two stages in a
statistical analysis, and in Sections \ref{sect:rawtoinput} and
\ref{sect:inputtomicro} we will define more clearly which quality aspect are improved
in which stage, and we show how to do this with \R{}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Some general background in \R{}}
We assume that the reader has some proficiency in \R{}. However, as a service
to the reader, below we summarize a few concepts which are fundamental to
working with \R{}, especially when working with ``dirty data''.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Variable types and indexing techniques}
\label{sect:indexing}
If you can choose to be proficient in just one \R{}-skill, it should be
indexing. By indexing we mean all the methods and tricks in \R{} that allow you
to select and manipulate data using \code{logical}, \code{integer} or named
indices. Since indexing skills are important for data cleaning, we quickly
review \code{vectors}, \code{data.frames} and things you can do with indices below.

The most basic variable in \R{} is a \code{vector}. An \R{} vector is a
sequence of ordered values of the same type. All basic operations in \R{} act
on vectors (think of the element-wise arithmetic, for example). The basic types
in \R{} are as follows.
\begin{center}
\begin{tabular}{ll}
  \code{numeric} & Numeric data (approximations of the real numbers, $\mathbb{R}$)\\
  \code{integer} & Integer data (whole numbers, $\mathbb{Z}$)\\
  \code{factor}  & Categorical data (simple classifications, like \emph{gender})\\
  \code{ordered} & Ordinal data (ordered classifications, like \emph{educational level})\\
  \code{character} & Character data (strings)\\
  \code{raw}  & Binary data\\
\end{tabular}
\end{center}
All basic operations in \R{} work element wise on vector where the shortest
argument is recycled if necessary. This goes for arithmetic operations
(addition, subtraction,$\ldots$), comparison operators (\code{==},
\code{<=},\ldots), logical operators (\code{\&}, \code{|}, \code{!},$\ldots$)
and basic math functions like \code{sin}, \code{cos}, \code{exp} and so on. 
If you want to brush up your basic knowledge of vector and recycling properties,
you can execute the following code and think about why it works the way it does.
<<eval=FALSE>>=
# vectors have variables of _one_ type
c(1,2,"three")
# shorter arguments are recycled
(1:3) * 2
(1:4) * c(1,2)
# warning! (why?)
(1:4) * (1:3)
@

Each element of a vector can be given a \code{name}. This can be done
by passing named arguments to the \code{c()} function or later with
the \code{names} function. Such names can be helpful giving meaning
to  your variables. For example consider the vector
<<>>=
x <- c("red","green","blue")
@
with the one below.
<<>>=
capColor = c(huey="red",duey="blue",louie="green")
@
Obviously the second version is much more suggestive of its meaning.
The names of a vector need not be unique, but in most applications
you'll want unique names (if any).

Elements of a vector can be chosen replaced using the square bracket operators
\code{[ ]} (more precisely, the \code{`[`} operator, but we'll skip technical
details).  The square brackets accept either a vector of names, index numbers,
or a logical.  In the case of a logical, the index is recycled if it is shorter
than the indexed vector. In the case of numerical indices, negative indices
omit, rather than select elements. Negative and positive indices are not allowed in the
same index vector. You may check the above by predicting and then
verifying the result of the following statements.
<<eval=FALSE>>=
capColor['louie']
names(capColor)[capColor == 'blue']
x <- c(4,7,6,5,2,8)
I <- x < 6
J <- x > 7
x[I|J]
x[c(TRUE,FALSE)]
x[c(-1,-2)]
@
Assigning values to vectors can be done in the same way. For example,
you may check that in the following assignment
<<eval>>=
x <- 1:10
x[c(TRUE,FALSE)] <- 1
@
every other value of \code{x} is replaced with \code{1}.

A \code{list} is a generalization of a vector in that it can contain objects of
different types, even other lists. There are two ways to index a \code{list}.
The single bracket operator always returns a \code{sublist} of the indexed
\code{list}.  That is, the resulting type is again a \code{list}. The
\code{double bracket} operator (\code{[[ ]]}) may only result in a single
\code{list} item, and it returns the object in the list itself. Besides
indexing, the dollar operator \code{\$} can be used to retrieve a single
element. To understand the above, check the results of the following
statements.
<<eval=FALSE>>=
L <- list(x = c(1:5), y=c('a','b','c'),z=capColor)
L[[2]]
L$y
L[c(1,3)]
L[c('x','y')]
L[['z']]
@
%
A \code{data.frame} is not much more than a \code{list} of vectors, possibly of
different types, but with every vector (now columns) of the same length. Since
\code{data.frames} are a type of list, indexing them with a single index returns
a sub-\code{data.frame}; that is, a \code{data.frame} with less columns.
Likewise, the dollar operator returns a vector, not a sub-\code{data.frame}.
Rows can be indexed using two indices in the bracket operator, separated by a
comma. The first index indicates rows, the second indicates columns.  If one of
the indices is left out, no selection is made (so everything is returned).  It
is important to realize that the result of a two-index selection is simplified
by \R{} simplified as much as possible. Hence, selecting a single column using
a two-index results in a vector. This may be switched off again using
\code{drop=FALSE} as an extra parameter. Here are some short examples
demonstrating the above.
<<eval=FALSE>>=
d <- data.frame(x = 1:10, y=letters[1:10],z=LETTERS[1:10])
d[1]
d[ ,1]
d[ ,'x',drop=FALSE]
d[c('x','z')]
d[d$x > 3,'y',drop=FALSE]
d[2, ]
@




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Special values}
\label{sect:specval}
Like almost
every other programming language, \R{} has a number of Special values that are
exceptions to the normal values of a type. These are \code{NA}, \code{NULL},
\code{$\pm$Inf} and \code{NaN}. Below, we quickly illustrate the meaning and
differences between them.
%
\begin{itemize}
\item[\code{NA}] Stands for \emph{not available}. \code{NA} is a placeholder
for a missing value.  All basic operations in \R{} handle \code{NA} without
crashing and mostly return \code{NA} as an answer whenever one of the input
arguments is \code{NA}. If you understand \code{NA}, you should be able to
predict the result of the following \R{} statements.
<<eval=FALSE>>=
NA + 1
sum(c(NA,1,2))
median(c(NA,1,2,3), na.rm=TRUE)
length(c(NA, 2, 3, 4))
3 == NA
NA == NA
TRUE | NA
@
The function \code{is.na} can be used to detect \code{NA}'s.

\item[\code{NULL}] You may think \code{NULL} as the empty set from
mathematics.  \code{NULL} is special since it has no \code{class} (its class
is \code{NULL}) and has length 0 so it does not take up any space in a vector.
In particular, if you understand \code{NULL}, the result of the following
statements should be clear to you without starting \R{}.
<<eval=FALSE>>=
length(c(1,2,NULL,4))
sum(c(1,2,NULL,4))
x <- NULL
c(x,2)
@
The function \code{is.null} can be used to detect \code{NULL} variables.

\item[\code{Inf}] Stands for \emph{infinity} and only applies to vectors of
class \code{numeric} and \code{integer} can never be \code{Inf}. This is
because the \code{Inf} in \R{} is directly derived from the international
standard for floating point arithmetic\cite{ieee:2008}. Technically, \code{Inf}
is a valid \code{numeric} that results from calculations like division of a
number by zero. Since \code{Inf} is a numeric, operations between \code{Inf}
and a finite numeric are well-defined and comparison operators work as
expected. If you understand \code{Inf}, the result of the following statements
should be clear to you.
<<eval=FALSE>>=
pi/0
2*Inf
Inf - 1e10
Inf + Inf
3 < -Inf
Inf == Inf
@

\item[\code{NaN}] Stands for \emph{not a number}. This is generally the result
of a calculation of which the result is unknown, but it is surely not a number.
In particular operations like \code{0/0}, \code{Inf-Inf} and \code{Inf/Inf} result
in \code{NaN}. Technically, \code{NaN} is of class numeric, which may seem odd
since it is used to indicate that something is \emph{not} numeric. Computations
involving numbers and \code{NaN} always result in \code{NaN}, so the result
of the following computations should be clear.
<<eval=FALSE>>=
NaN + 1
exp(NaN)
@
The function \code{is.nan} can be used to detect \code{NaN}'s.
\end{itemize}

\begin{tip}{Tip}
The function \code{is.finite} checks a  vector for the occurrence of 
any non-numerical or special values.
\end{tip}



\subsection*{Exercises}

\begin{exercise}
Predict the result of the following \R{} statements.
\begin{subex}
\item \code{exp(-Inf)}
\item \code{NA == NA}
\item \code{NA == NULL}
\item \code{NULL == NULL}
\item \code{NA \& FALSE}
\end{subex}
\end{exercise}


\begin{exercise}
  In which of the steps outlined in Figure \ref{fig:steps} would you perform the following activities?
  \begin{subex}
    \item Estimating values for empty fields.
    \item Setting the font for the title of a histogram.
    \item Rewrite a column of categorical variables so that they are al written in capitals.
    \item Use the \code{knitr} package\cite{xi:2013} to produce a statistical report.
    \item Exporting data from \code{Excel} to \code{csv}. 
  \end{subex}
\end{exercise}

